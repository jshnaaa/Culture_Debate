"""
è®¾ç½®å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„å’Œé…ç½®æ–‡ä»¶
"""

import os
import yaml
import json
from pathlib import Path

def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = [
        "config",
        "output",
        "cache",
        "logs"
    ]

    for dir_name in directories:
        Path(dir_name).mkdir(exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {dir_name}")

def create_global_config():
    """åˆ›å»ºå…¨å±€é…ç½®æ–‡ä»¶"""
    config = {
        "hf_token": "",  # éœ€è¦ç”¨æˆ·å¡«å…¥HuggingFace token
        "cache_dir": "./cache",
        "max_active_agents": 3,
        "idle_timeout": 300.0,
        "memory_threshold": 0.8,
        "message_bus": {
            "max_queue_size": 1000,
            "message_timeout": 30.0,
            "retry_attempts": 3
        },
        "logging": {
            "level": "INFO",
            "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        }
    }

    config_path = Path("config/global_config.yaml")
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)

    print(f"âœ… åˆ›å»ºå…¨å±€é…ç½®: {config_path}")

def create_agent_configs():
    """åˆ›å»ºæ™ºèƒ½ä½“é…ç½®æ–‡ä»¶"""

    # åŸºç£æ•™æ–‡åŒ–æ™ºèƒ½ä½“é…ç½®
    christian_config = {
        "model": {
            "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
            "cache_dir": "./cache",
            "torch_dtype": "bfloat16",
            "device_map": "auto",
            "max_new_tokens": 512,
            "temperature": 0.0,
            "max_input_length": 2048
        },
        "cultural": {
            "cultural_values": ["ä¸ªäººè‡ªç”±", "äººæƒ", "å¹³ç­‰", "æ°‘ä¸»", "ä¸ªäººè´£ä»»"],
            "social_norms": {
                "å•†åŠ¡ç©¿ç€": "æ­£å¼åœºåˆç©¿ç€å¾—ä½“ï¼Œæ—¥å¸¸å¯ä»¥ç›¸å¯¹éšæ„",
                "ç¤¾äº¤äº’åŠ¨": "ç›´æ¥æ²Ÿé€šï¼Œæ¡æ‰‹é—®å€™ï¼Œæ³¨é‡ä¸ªäººç©ºé—´",
                "å†³ç­–æ–¹å¼": "ä¸ªäººå†³ç­–ï¼Œè€ƒè™‘ä¸ªäººåˆ©ç›Šå’Œæƒåˆ©"
            },
            "communication_style": {
                "ç›´æ¥æ€§": "é«˜",
                "æ­£å¼ç¨‹åº¦": "ä¸­ç­‰"
            },
            "decision_factors": ["ä¸ªäººæƒåˆ©å’Œè‡ªç”±", "æ³•å¾‹å’Œè§„åˆ™", "å…¬å¹³æ€§"],
            "prompt_templates": {
                "initial_decision": "ä½œä¸ºåŸºç£æ•™æ–‡åŒ–ä»£è¡¨ï¼Œè¯„ä¼°è¡Œä¸ºçš„ç¤¾ä¼šå¯æ¥å—æ€§...",
                "feedback": "åŸºäºåŸºç£æ•™ä»·å€¼è§‚æä¾›åé¦ˆ...",
                "final_decision": "åšå‡ºæœ€ç»ˆåˆ¤æ–­..."
            }
        },
        "custom": {}
    }

    # ä¼Šæ–¯å…°æ–‡åŒ–æ™ºèƒ½ä½“é…ç½®
    islamic_config = {
        "model": {
            "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
            "cache_dir": "./cache",
            "torch_dtype": "bfloat16",
            "device_map": "auto",
            "max_new_tokens": 512,
            "temperature": 0.0,
            "max_input_length": 2048
        },
        "cultural": {
            "cultural_values": ["è°¦é€Š", "æ•¬ç•", "å®¶åº­è´£ä»»", "ç¤¾ä¼šç§©åº", "è¯šå®"],
            "social_norms": {
                "ç©¿ç€è§„èŒƒ": "ä¿å®ˆç©¿ç€ï¼Œç‰¹åˆ«æ˜¯å…¬å…±åœºåˆ",
                "ç¤¾äº¤äº’åŠ¨": "åŒæ€§æ¡æ‰‹ï¼Œå¼‚æ€§é¿å…èº«ä½“æ¥è§¦",
                "å•†åŠ¡ç¤¼ä»ª": "æ³¨é‡ä¼ ç»Ÿå’Œå°Šé‡"
            },
            "communication_style": {
                "ç›´æ¥æ€§": "ä¸­ç­‰",
                "æ­£å¼ç¨‹åº¦": "é«˜"
            },
            "decision_factors": ["å®—æ•™æ•™ä¹‰", "å®¶åº­å’Œç¤¾åŒºåˆ©ç›Š", "ä¼ ç»Ÿå’Œä¹ ä¿—"],
            "prompt_templates": {
                "initial_decision": "ä½œä¸ºä¼Šæ–¯å…°æ–‡åŒ–ä»£è¡¨ï¼Œè¯„ä¼°è¡Œä¸ºçš„ç¤¾ä¼šå¯æ¥å—æ€§...",
                "feedback": "åŸºäºä¼Šæ–¯å…°ä»·å€¼è§‚æä¾›åé¦ˆ...",
                "final_decision": "åšå‡ºæœ€ç»ˆåˆ¤æ–­..."
            }
        },
        "custom": {}
    }

    # å…¶ä»–æ–‡åŒ–æ™ºèƒ½ä½“é…ç½®ï¼ˆç®€åŒ–ç‰ˆï¼‰
    other_configs = {
        "cultural_buddhist": {
            "model": {"model_id": "google/gemma-2-9b-it", "cache_dir": "./cache", "torch_dtype": "bfloat16"},
            "cultural": {"cultural_values": ["å†…å¿ƒå¹³é™", "æ…ˆæ‚²", "ç®€æœ´", "å’Œè°"]}
        },
        "cultural_hindu": {
            "model": {"model_id": "meta-llama/Meta-Llama-3-8B-Instruct", "cache_dir": "./cache", "torch_dtype": "bfloat16"},
            "cultural": {"cultural_values": ["è¾¾æ‘©", "å®¶åº­è´£ä»»", "ç²¾ç¥ä¿®å…»", "ä¼ ç»Ÿä»ªå¼"]}
        },
        "cultural_traditional": {
            "model": {"model_id": "meta-llama/Meta-Llama-3-8B-Instruct", "cache_dir": "./cache", "torch_dtype": "bfloat16"},
            "cultural": {"cultural_values": ["è‡ªç„¶å’Œè°", "ç¥–å…ˆå´‡æ‹œ", "éƒ¨è½å›¢ç»“", "ä¼ ç»Ÿæ™ºæ…§"]}
        }
    }

    # ä¿å­˜é…ç½®æ–‡ä»¶
    configs = {
        "cultural_christian": christian_config,
        "cultural_islamic": islamic_config,
        **other_configs
    }

    for agent_type, config in configs.items():
        config_path = Path(f"config/{agent_type}_config.yaml")
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        print(f"âœ… åˆ›å»ºæ™ºèƒ½ä½“é…ç½®: {config_path}")

def create_run_script():
    """åˆ›å»ºè¿è¡Œè„šæœ¬"""
    script_content = '''#!/bin/bash

# å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¿è¡Œè„šæœ¬

echo "ğŸš€ å¯åŠ¨å¤šæ™ºèƒ½ä½“æ–‡åŒ–å¯¹é½ç³»ç»Ÿ"

# æ£€æŸ¥Pythonç¯å¢ƒ
if ! command -v python &> /dev/null; then
    echo "âŒ æœªæ‰¾åˆ°Pythonï¼Œè¯·ç¡®ä¿Pythonå·²å®‰è£…"
    exit 1
fi

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
if [ ! -f "data/normad.jsonl" ]; then
    echo "âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ data/normad.jsonl"
    exit 1
fi

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p output logs

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

echo "ğŸ“Š å¼€å§‹å¤„ç†NORMADæ•°æ®é›†..."

# è¿è¡Œæ¨ç†ï¼ˆé»˜è®¤å¤„ç†å‰10é¡¹ç”¨äºæµ‹è¯•ï¼‰
python run_multi_agent_inference.py \\
    --input_path data/normad.jsonl \\
    --output_path output/multi_agent_results.jsonl \\
    --config_dir config \\
    --log_level INFO \\
    --max_items 10 \\
    --start_from 0

echo "âœ… å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨ output/multi_agent_results.jsonl"
'''

    script_path = Path("run_inference.sh")
    with open(script_path, 'w') as f:
        f.write(script_content)

    # è®¾ç½®æ‰§è¡Œæƒé™
    os.chmod(script_path, 0o755)
    print(f"âœ… åˆ›å»ºè¿è¡Œè„šæœ¬: {script_path}")

def main():
    """ä¸»è®¾ç½®å‡½æ•°"""
    print("ğŸ”§ è®¾ç½®å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ...")

    # åˆ›å»ºç›®å½•ç»“æ„
    create_directories()

    # åˆ›å»ºé…ç½®æ–‡ä»¶
    create_global_config()
    create_agent_configs()

    # åˆ›å»ºè¿è¡Œè„šæœ¬
    create_run_script()

    print("\nâœ… ç³»ç»Ÿè®¾ç½®å®Œæˆï¼")
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œï¼š")
    print("1. ç¼–è¾‘ config/global_config.yamlï¼Œå¡«å…¥ä½ çš„HuggingFace token")
    print("2. ç¡®ä¿æ•°æ®æ–‡ä»¶ data/normad.jsonl å­˜åœ¨")
    print("3. è¿è¡Œæµ‹è¯•ï¼špython test_system.py")
    print("4. è¿è¡Œæ¨ç†ï¼š./run_inference.sh æˆ– python run_multi_agent_inference.py")

    print("\nâš ï¸  æ³¨æ„äº‹é¡¹ï¼š")
    print("- ç¡®ä¿æœ‰è¶³å¤Ÿçš„GPUå†…å­˜ï¼ˆå»ºè®®16GB+ï¼‰")
    print("- é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œéœ€è¦ç½‘ç»œè¿æ¥")
    print("- å¯ä»¥é€šè¿‡ --max_items å‚æ•°æ§åˆ¶å¤„ç†çš„æ•°æ®é‡")

if __name__ == "__main__":
    main()